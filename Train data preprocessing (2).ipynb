{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"JobDataTranslated.csv\")\n",
    "keyWords = pd.read_csv(\"words_set_long.csv\")\n",
    "keyWords_short = pd.read_csv(\"words_set_short.csv\")\n",
    "Data=Data[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a thing to clean input\n",
    "#Data['Job Description'].apply(lambda x: x.lower())\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    # removing paragraph numbers\n",
    "    text = re.sub('[0-9]+.\\t','',str(text))\n",
    "    # removing new line characters\n",
    "    text = re.sub('\\n ','',str(text))\n",
    "    text = re.sub('\\n',' ',str(text))\n",
    "    # removing apostrophes\n",
    "    text = re.sub(\"'s\",'',str(text))\n",
    "    # removing hyphens\n",
    "    text = re.sub(\"-\",' ',str(text))\n",
    "    text = re.sub(\"â€” \",'',str(text))\n",
    "    # removing quotation marks\n",
    "    text = re.sub('\\\"','',str(text))\n",
    "    # removing salutations\n",
    "    text = re.sub(\"Mr\\.\",'Mr',str(text))\n",
    "    text = re.sub(\"Mrs\\.\",'Mrs',str(text))\n",
    "    # removing any reference to outside text\n",
    "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(text))\n",
    "    \n",
    "    return text\n",
    "\n",
    "# preprocessing speeches\n",
    "Data['Cleaned Job Description'] = Data['Job Description'].apply(clean)\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    global punctuation\n",
    "    for p in punctuation:\n",
    "        s = s.replace(p, '')\n",
    "    return s\n",
    "\n",
    "#Data['Cleaned Job Description'] = Data['Cleaned Job Description'].map(remove_punctuation)\n",
    "\n",
    "Data['Cleaned Job Description'] = Data['Cleaned Job Description'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kWords=[keyWords_short['0'][i] for i in range(len(keyWords_short))]\n",
    "#kWords=[keyWords['0'][i] for i in range(len(keyWords))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data['Cleaned Job Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" this thing allows us to find all words start indexes\"\"\"\n",
    "def find_all(text, sub):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = text.find(sub, start)\n",
    "        if start == -1: return\n",
    "        yield start\n",
    "        start += len(sub) # use start += 1 to find overlapping matches\n",
    "\n",
    "\"\"\"all words start indexes for list of words\"\"\"\n",
    "def find_all_in_list(text, subs: list):\n",
    "    l=[]\n",
    "    for i in subs:\n",
    "        l.append(list(find_all(text,i)))\n",
    "    m = [l[j][k] for j in range(len(l)) for k in range(len(l[j]))]\n",
    "    return m\n",
    "\n",
    "\n",
    "\"gives a sentence for an index of word inside\"\n",
    "def get_sentence(num, text ):\n",
    "    l= find_all_in_list(text, ['.','!','?',';'])\n",
    "    if (len(l)==0):\n",
    "        return -1\n",
    "    \n",
    "    l.sort()\n",
    "    if (num <l[0]):\n",
    "        return text[0:l[0]]\n",
    "    elif (num>l[-1]):\n",
    "        return text[l[-1]+1:]\n",
    "    \n",
    "    x=[i for i in range(len(l)) if l[i]<num and l[i+1]>num]\n",
    "    return (text[l[x[0]]+1:l[x[0]+1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for d in Data['Cleaned Job Description'] :\n",
    "    for i in kWords:\n",
    "        if d.find(i)!=-1:\n",
    "            #print(d.find(i),d.find(i)+len(i), get_sentence(d.find(i),d) ,'hui',i)\n",
    "            s = (get_sentence(d.find(i),d))\n",
    "            if (s!=-1):\n",
    "                l.append((s ,{\"entities\": [(s.find(i),s.find(i)+len(i), \"SKILL\")]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' you are partly responsible for the implementation and you will mainly perform system management activities',\n",
       "  {'entities': [(86, 107, 'SKILL')]}),\n",
       " (' experience in installation technology', {'entities': [(15, 38, 'SKILL')]}),\n",
       " (' and do you want to be trained as an experienced service technician',\n",
       "  {'entities': [(49, 67, 'SKILL')]}),\n",
       " (' as a starter you will be trained within the organization as a service technician in heating technology',\n",
       "  {'entities': [(85, 103, 'SKILL')]}),\n",
       " (' and do you want to be trained as an experienced service technician',\n",
       "  {'entities': [(37, 67, 'SKILL')]}),\n",
       " (' as an apprentice service technician you work in a pleasant, dynamic team with a pleasant working atmosphere',\n",
       "  {'entities': [(7, 36, 'SKILL')]}),\n",
       " (' it is an advantage if you have completed an mbo level 2 education in electricity',\n",
       "  {'entities': [(45, 54, 'SKILL')]}),\n",
       " (' as a technical support employee, we give you the right intensive training and coaching',\n",
       "  {'entities': [(6, 23, 'SKILL')]}),\n",
       " (' you have a strong administrative background',\n",
       "  {'entities': [(19, 44, 'SKILL')]}),\n",
       " (' your administrative experience will help you with this',\n",
       "  {'entities': [(6, 31, 'SKILL')]})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7183"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"training_set_1.txt\", \"w\") as fp:\n",
    "    json.dump(l, fp)\n",
    "\n",
    "    \n",
    "# that's how you load this thing, the format will be mimimally diffreent so either fix it or just merge 2 notebooks\n",
    "#with open(\"training_set_1.txt\", \"r\") as fp:\n",
    "    #b = json.load(fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
